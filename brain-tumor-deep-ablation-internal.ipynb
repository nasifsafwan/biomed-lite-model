{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a54fbeb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-21T19:00:43.226723Z",
     "iopub.status.busy": "2025-09-21T19:00:43.226216Z",
     "iopub.status.idle": "2025-09-21T23:04:48.395853Z",
     "shell.execute_reply": "2025-09-21T23:04:48.395030Z"
    },
    "papermill": {
     "duration": 14645.175785,
     "end_time": "2025-09-21T23:04:48.397287",
     "exception": false,
     "start_time": "2025-09-21T19:00:43.221502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "===== Training: baseline =====\n",
      "attention_mode=none | guided_loss=False | head_variant=base\n",
      "[baseline] Epoch 01/10 | Train: loss=0.9308 acc=0.6927 P/R/F1=0.691/0.701/0.694 AUC=0.901 | Val: loss=0.7558 acc=0.8283 P/R/F1=0.835/0.834/0.829 AUC=0.961 | lr=0.000293\n",
      "âœ… [baseline] New best saved @ /kaggle/working/tumornet_runs/ablation_baseline/best.pt (val_acc=0.8283)\n",
      "[baseline] Epoch 02/10 | Train: loss=0.6388 acc=0.8884 P/R/F1=0.891/0.892/0.891 AUC=0.982 | Val: loss=0.6528 acc=0.8833 P/R/F1=0.887/0.889/0.884 AUC=0.979 | lr=0.000274\n",
      "âœ… [baseline] New best saved @ /kaggle/working/tumornet_runs/ablation_baseline/best.pt (val_acc=0.8833)\n",
      "[baseline] Epoch 03/10 | Train: loss=0.5721 acc=0.9247 P/R/F1=0.926/0.927/0.926 AUC=0.990 | Val: loss=0.5729 acc=0.9288 P/R/F1=0.927/0.931/0.928 AUC=0.990 | lr=0.000244\n",
      "âœ… [baseline] New best saved @ /kaggle/working/tumornet_runs/ablation_baseline/best.pt (val_acc=0.9288)\n",
      "[baseline] Epoch 04/10 | Train: loss=0.5371 acc=0.9456 P/R/F1=0.946/0.947/0.946 AUC=0.994 | Val: loss=0.5716 acc=0.9338 P/R/F1=0.932/0.937/0.934 AUC=0.988 | lr=0.000207\n",
      "âœ… [baseline] New best saved @ /kaggle/working/tumornet_runs/ablation_baseline/best.pt (val_acc=0.9338)\n",
      "[baseline] Epoch 05/10 | Train: loss=0.5084 acc=0.9620 P/R/F1=0.962/0.963/0.963 AUC=0.997 | Val: loss=0.5508 acc=0.9490 P/R/F1=0.947/0.951/0.948 AUC=0.991 | lr=0.000165\n",
      "âœ… [baseline] New best saved @ /kaggle/working/tumornet_runs/ablation_baseline/best.pt (val_acc=0.9490)\n",
      "[baseline] Epoch 06/10 | Train: loss=0.4884 acc=0.9734 P/R/F1=0.974/0.974/0.974 AUC=0.998 | Val: loss=0.5369 acc=0.9530 P/R/F1=0.951/0.955/0.953 AUC=0.991 | lr=0.000123\n",
      "âœ… [baseline] New best saved @ /kaggle/working/tumornet_runs/ablation_baseline/best.pt (val_acc=0.9530)\n",
      "[baseline] Epoch 07/10 | Train: loss=0.4770 acc=0.9788 P/R/F1=0.979/0.979/0.979 AUC=0.999 | Val: loss=0.5384 acc=0.9525 P/R/F1=0.951/0.955/0.952 AUC=0.990 | lr=0.000086\n",
      "[baseline] Epoch 08/10 | Train: loss=0.4654 acc=0.9848 P/R/F1=0.985/0.985/0.985 AUC=1.000 | Val: loss=0.5229 acc=0.9596 P/R/F1=0.957/0.962/0.959 AUC=0.994 | lr=0.000056\n",
      "âœ… [baseline] New best saved @ /kaggle/working/tumornet_runs/ablation_baseline/best.pt (val_acc=0.9596)\n",
      "[baseline] Epoch 09/10 | Train: loss=0.4588 acc=0.9881 P/R/F1=0.988/0.988/0.988 AUC=1.000 | Val: loss=0.5176 acc=0.9616 P/R/F1=0.960/0.964/0.961 AUC=0.994 | lr=0.000037\n",
      "âœ… [baseline] New best saved @ /kaggle/working/tumornet_runs/ablation_baseline/best.pt (val_acc=0.9616)\n",
      "[baseline] Epoch 10/10 | Train: loss=0.4556 acc=0.9907 P/R/F1=0.991/0.991/0.991 AUC=1.000 | Val: loss=0.5120 acc=0.9682 P/R/F1=0.966/0.971/0.968 AUC=0.995 | lr=0.000030\n",
      "âœ… [baseline] New best saved @ /kaggle/working/tumornet_runs/ablation_baseline/best.pt (val_acc=0.9682)\n",
      "\n",
      "ðŸ“Š Test Metrics â†’ Acc: 0.9606 | Precision: 0.9588 | Recall: 0.9655 | F1: 0.9611 | AUC: 0.9916\n",
      "\n",
      "===== Training: channel_only =====\n",
      "attention_mode=ch | guided_loss=False | head_variant=base\n",
      "[channel_only] Epoch 01/10 | Train: loss=0.9617 acc=0.6752 P/R/F1=0.677/0.683/0.679 AUC=0.889 | Val: loss=0.7918 acc=0.8081 P/R/F1=0.817/0.805/0.807 AUC=0.948 | lr=0.000293\n",
      "âœ… [channel_only] New best saved @ /kaggle/working/tumornet_runs/ablation_channel_only/best.pt (val_acc=0.8081)\n",
      "[channel_only] Epoch 02/10 | Train: loss=0.6884 acc=0.8589 P/R/F1=0.862/0.865/0.863 AUC=0.972 | Val: loss=0.6673 acc=0.8828 P/R/F1=0.885/0.882/0.879 AUC=0.974 | lr=0.000274\n",
      "âœ… [channel_only] New best saved @ /kaggle/working/tumornet_runs/ablation_channel_only/best.pt (val_acc=0.8828)\n",
      "[channel_only] Epoch 03/10 | Train: loss=0.5972 acc=0.9125 P/R/F1=0.914/0.916/0.915 AUC=0.987 | Val: loss=0.6458 acc=0.8884 P/R/F1=0.890/0.893/0.889 AUC=0.982 | lr=0.000244\n",
      "âœ… [channel_only] New best saved @ /kaggle/working/tumornet_runs/ablation_channel_only/best.pt (val_acc=0.8884)\n",
      "[channel_only] Epoch 04/10 | Train: loss=0.5460 acc=0.9400 P/R/F1=0.941/0.942/0.941 AUC=0.993 | Val: loss=0.5808 acc=0.9268 P/R/F1=0.926/0.933/0.927 AUC=0.989 | lr=0.000207\n",
      "âœ… [channel_only] New best saved @ /kaggle/working/tumornet_runs/ablation_channel_only/best.pt (val_acc=0.9268)\n",
      "[channel_only] Epoch 05/10 | Train: loss=0.5136 acc=0.9609 P/R/F1=0.962/0.962/0.962 AUC=0.996 | Val: loss=0.5656 acc=0.9313 P/R/F1=0.931/0.934/0.932 AUC=0.991 | lr=0.000165\n",
      "âœ… [channel_only] New best saved @ /kaggle/working/tumornet_runs/ablation_channel_only/best.pt (val_acc=0.9313)\n",
      "[channel_only] Epoch 06/10 | Train: loss=0.4999 acc=0.9656 P/R/F1=0.966/0.967/0.966 AUC=0.998 | Val: loss=0.5560 acc=0.9439 P/R/F1=0.943/0.948/0.944 AUC=0.990 | lr=0.000123\n",
      "âœ… [channel_only] New best saved @ /kaggle/working/tumornet_runs/ablation_channel_only/best.pt (val_acc=0.9439)\n",
      "[channel_only] Epoch 07/10 | Train: loss=0.4783 acc=0.9773 P/R/F1=0.978/0.978/0.978 AUC=0.999 | Val: loss=0.5492 acc=0.9510 P/R/F1=0.949/0.954/0.951 AUC=0.986 | lr=0.000086\n",
      "âœ… [channel_only] New best saved @ /kaggle/working/tumornet_runs/ablation_channel_only/best.pt (val_acc=0.9510)\n",
      "[channel_only] Epoch 08/10 | Train: loss=0.4716 acc=0.9818 P/R/F1=0.982/0.982/0.982 AUC=0.999 | Val: loss=0.5301 acc=0.9556 P/R/F1=0.954/0.958/0.956 AUC=0.992 | lr=0.000056\n",
      "âœ… [channel_only] New best saved @ /kaggle/working/tumornet_runs/ablation_channel_only/best.pt (val_acc=0.9556)\n",
      "[channel_only] Epoch 09/10 | Train: loss=0.4589 acc=0.9887 P/R/F1=0.989/0.989/0.989 AUC=1.000 | Val: loss=0.5265 acc=0.9596 P/R/F1=0.958/0.962/0.959 AUC=0.991 | lr=0.000037\n",
      "âœ… [channel_only] New best saved @ /kaggle/working/tumornet_runs/ablation_channel_only/best.pt (val_acc=0.9596)\n",
      "[channel_only] Epoch 10/10 | Train: loss=0.4546 acc=0.9910 P/R/F1=0.991/0.991/0.991 AUC=1.000 | Val: loss=0.5244 acc=0.9601 P/R/F1=0.958/0.962/0.960 AUC=0.992 | lr=0.000030\n",
      "âœ… [channel_only] New best saved @ /kaggle/working/tumornet_runs/ablation_channel_only/best.pt (val_acc=0.9601)\n",
      "\n",
      "ðŸ“Š Test Metrics â†’ Acc: 0.9596 | Precision: 0.9579 | Recall: 0.9643 | F1: 0.9602 | AUC: 0.9900\n",
      "\n",
      "===== Training: spatial_only =====\n",
      "attention_mode=sp | guided_loss=False | head_variant=base\n",
      "[spatial_only] Epoch 01/10 | Train: loss=0.9288 acc=0.6985 P/R/F1=0.699/0.709/0.701 AUC=0.902 | Val: loss=0.7105 acc=0.8434 P/R/F1=0.841/0.850/0.844 AUC=0.968 | lr=0.000293\n",
      "âœ… [spatial_only] New best saved @ /kaggle/working/tumornet_runs/ablation_spatial_only/best.pt (val_acc=0.8434)\n",
      "[spatial_only] Epoch 02/10 | Train: loss=0.6550 acc=0.8799 P/R/F1=0.881/0.884/0.882 AUC=0.979 | Val: loss=0.6445 acc=0.9010 P/R/F1=0.900/0.903/0.901 AUC=0.976 | lr=0.000274\n",
      "âœ… [spatial_only] New best saved @ /kaggle/working/tumornet_runs/ablation_spatial_only/best.pt (val_acc=0.9010)\n",
      "[spatial_only] Epoch 03/10 | Train: loss=0.5786 acc=0.9235 P/R/F1=0.925/0.926/0.925 AUC=0.990 | Val: loss=0.6170 acc=0.9076 P/R/F1=0.905/0.913/0.907 AUC=0.984 | lr=0.000244\n",
      "âœ… [spatial_only] New best saved @ /kaggle/working/tumornet_runs/ablation_spatial_only/best.pt (val_acc=0.9076)\n",
      "[spatial_only] Epoch 04/10 | Train: loss=0.5460 acc=0.9396 P/R/F1=0.940/0.942/0.941 AUC=0.994 | Val: loss=0.5725 acc=0.9374 P/R/F1=0.936/0.940/0.938 AUC=0.988 | lr=0.000207\n",
      "âœ… [spatial_only] New best saved @ /kaggle/working/tumornet_runs/ablation_spatial_only/best.pt (val_acc=0.9374)\n",
      "[spatial_only] Epoch 05/10 | Train: loss=0.5188 acc=0.9558 P/R/F1=0.956/0.957/0.957 AUC=0.996 | Val: loss=0.5523 acc=0.9394 P/R/F1=0.938/0.941/0.939 AUC=0.992 | lr=0.000165\n",
      "âœ… [spatial_only] New best saved @ /kaggle/working/tumornet_runs/ablation_spatial_only/best.pt (val_acc=0.9394)\n",
      "[spatial_only] Epoch 06/10 | Train: loss=0.4988 acc=0.9678 P/R/F1=0.968/0.969/0.969 AUC=0.997 | Val: loss=0.5435 acc=0.9470 P/R/F1=0.945/0.950/0.947 AUC=0.992 | lr=0.000123\n",
      "âœ… [spatial_only] New best saved @ /kaggle/working/tumornet_runs/ablation_spatial_only/best.pt (val_acc=0.9470)\n",
      "[spatial_only] Epoch 07/10 | Train: loss=0.4813 acc=0.9767 P/R/F1=0.977/0.977/0.977 AUC=0.998 | Val: loss=0.5435 acc=0.9515 P/R/F1=0.949/0.955/0.951 AUC=0.989 | lr=0.000086\n",
      "âœ… [spatial_only] New best saved @ /kaggle/working/tumornet_runs/ablation_spatial_only/best.pt (val_acc=0.9515)\n",
      "[spatial_only] Epoch 08/10 | Train: loss=0.4722 acc=0.9815 P/R/F1=0.982/0.982/0.982 AUC=0.999 | Val: loss=0.5204 acc=0.9616 P/R/F1=0.960/0.964/0.962 AUC=0.991 | lr=0.000056\n",
      "âœ… [spatial_only] New best saved @ /kaggle/working/tumornet_runs/ablation_spatial_only/best.pt (val_acc=0.9616)\n",
      "[spatial_only] Epoch 09/10 | Train: loss=0.4633 acc=0.9864 P/R/F1=0.987/0.987/0.987 AUC=1.000 | Val: loss=0.5132 acc=0.9646 P/R/F1=0.963/0.967/0.965 AUC=0.993 | lr=0.000037\n",
      "âœ… [spatial_only] New best saved @ /kaggle/working/tumornet_runs/ablation_spatial_only/best.pt (val_acc=0.9646)\n",
      "[spatial_only] Epoch 10/10 | Train: loss=0.4581 acc=0.9894 P/R/F1=0.990/0.990/0.990 AUC=1.000 | Val: loss=0.5123 acc=0.9646 P/R/F1=0.963/0.967/0.964 AUC=0.995 | lr=0.000030\n",
      "\n",
      "ðŸ“Š Test Metrics â†’ Acc: 0.9566 | Precision: 0.9562 | Recall: 0.9612 | F1: 0.9575 | AUC: 0.9889\n",
      "\n",
      "===== Training: cbam =====\n",
      "attention_mode=cbam | guided_loss=False | head_variant=base\n",
      "[cbam] Epoch 01/10 | Train: loss=0.8958 acc=0.7264 P/R/F1=0.728/0.735/0.730 AUC=0.916 | Val: loss=0.7976 acc=0.8000 P/R/F1=0.815/0.809/0.800 AUC=0.965 | lr=0.000293\n",
      "âœ… [cbam] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam/best.pt (val_acc=0.8000)\n",
      "[cbam] Epoch 02/10 | Train: loss=0.6561 acc=0.8802 P/R/F1=0.882/0.885/0.883 AUC=0.978 | Val: loss=0.6916 acc=0.8626 P/R/F1=0.866/0.859/0.861 AUC=0.971 | lr=0.000274\n",
      "âœ… [cbam] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam/best.pt (val_acc=0.8626)\n",
      "[cbam] Epoch 03/10 | Train: loss=0.5846 acc=0.9177 P/R/F1=0.919/0.920/0.920 AUC=0.989 | Val: loss=0.6374 acc=0.8995 P/R/F1=0.903/0.905/0.901 AUC=0.978 | lr=0.000244\n",
      "âœ… [cbam] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam/best.pt (val_acc=0.8995)\n",
      "[cbam] Epoch 04/10 | Train: loss=0.5460 acc=0.9414 P/R/F1=0.942/0.943/0.943 AUC=0.993 | Val: loss=0.6038 acc=0.9096 P/R/F1=0.910/0.914/0.910 AUC=0.984 | lr=0.000207\n",
      "âœ… [cbam] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam/best.pt (val_acc=0.9096)\n",
      "[cbam] Epoch 05/10 | Train: loss=0.5285 acc=0.9500 P/R/F1=0.951/0.952/0.951 AUC=0.995 | Val: loss=0.5707 acc=0.9333 P/R/F1=0.932/0.937/0.933 AUC=0.989 | lr=0.000165\n",
      "âœ… [cbam] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam/best.pt (val_acc=0.9333)\n",
      "[cbam] Epoch 06/10 | Train: loss=0.5103 acc=0.9585 P/R/F1=0.959/0.960/0.959 AUC=0.997 | Val: loss=0.5638 acc=0.9384 P/R/F1=0.938/0.942/0.939 AUC=0.988 | lr=0.000123\n",
      "âœ… [cbam] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam/best.pt (val_acc=0.9384)\n",
      "[cbam] Epoch 07/10 | Train: loss=0.4903 acc=0.9719 P/R/F1=0.972/0.972/0.972 AUC=0.998 | Val: loss=0.5577 acc=0.9404 P/R/F1=0.939/0.943/0.940 AUC=0.989 | lr=0.000086\n",
      "âœ… [cbam] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam/best.pt (val_acc=0.9404)\n",
      "[cbam] Epoch 08/10 | Train: loss=0.4762 acc=0.9771 P/R/F1=0.978/0.978/0.978 AUC=0.999 | Val: loss=0.5426 acc=0.9515 P/R/F1=0.950/0.954/0.951 AUC=0.990 | lr=0.000056\n",
      "âœ… [cbam] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam/best.pt (val_acc=0.9515)\n",
      "[cbam] Epoch 09/10 | Train: loss=0.4684 acc=0.9829 P/R/F1=0.983/0.983/0.983 AUC=0.999 | Val: loss=0.5281 acc=0.9621 P/R/F1=0.960/0.965/0.962 AUC=0.992 | lr=0.000037\n",
      "âœ… [cbam] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam/best.pt (val_acc=0.9621)\n",
      "[cbam] Epoch 10/10 | Train: loss=0.4631 acc=0.9853 P/R/F1=0.986/0.986/0.986 AUC=0.999 | Val: loss=0.5318 acc=0.9576 P/R/F1=0.956/0.961/0.958 AUC=0.991 | lr=0.000030\n",
      "\n",
      "ðŸ“Š Test Metrics â†’ Acc: 0.9525 | Precision: 0.9524 | Recall: 0.9584 | F1: 0.9538 | AUC: 0.9887\n",
      "\n",
      "===== Training: cbam_guided =====\n",
      "attention_mode=gcsa | guided_loss=False | head_variant=base\n",
      "[cbam_guided] Epoch 01/10 | Train: loss=0.8925 acc=0.7287 P/R/F1=0.731/0.737/0.733 AUC=0.916 | Val: loss=0.7725 acc=0.8172 P/R/F1=0.825/0.823/0.819 AUC=0.959 | lr=0.000293\n",
      "âœ… [cbam_guided] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam_guided/best.pt (val_acc=0.8172)\n",
      "[cbam_guided] Epoch 02/10 | Train: loss=0.6312 acc=0.8909 P/R/F1=0.892/0.894/0.893 AUC=0.982 | Val: loss=0.6310 acc=0.9020 P/R/F1=0.901/0.907/0.903 AUC=0.982 | lr=0.000274\n",
      "âœ… [cbam_guided] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam_guided/best.pt (val_acc=0.9020)\n",
      "[cbam_guided] Epoch 03/10 | Train: loss=0.5654 acc=0.9288 P/R/F1=0.930/0.931/0.930 AUC=0.991 | Val: loss=0.6519 acc=0.8924 P/R/F1=0.895/0.899/0.893 AUC=0.980 | lr=0.000244\n",
      "[cbam_guided] Epoch 04/10 | Train: loss=0.5347 acc=0.9464 P/R/F1=0.947/0.948/0.947 AUC=0.995 | Val: loss=0.5773 acc=0.9263 P/R/F1=0.927/0.927/0.925 AUC=0.991 | lr=0.000207\n",
      "âœ… [cbam_guided] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam_guided/best.pt (val_acc=0.9263)\n",
      "[cbam_guided] Epoch 05/10 | Train: loss=0.5080 acc=0.9612 P/R/F1=0.962/0.962/0.962 AUC=0.997 | Val: loss=0.6054 acc=0.9202 P/R/F1=0.922/0.926/0.922 AUC=0.980 | lr=0.000165\n",
      "[cbam_guided] Epoch 06/10 | Train: loss=0.4918 acc=0.9709 P/R/F1=0.971/0.972/0.972 AUC=0.998 | Val: loss=0.5372 acc=0.9510 P/R/F1=0.950/0.953/0.951 AUC=0.992 | lr=0.000123\n",
      "âœ… [cbam_guided] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam_guided/best.pt (val_acc=0.9510)\n",
      "[cbam_guided] Epoch 07/10 | Train: loss=0.4805 acc=0.9767 P/R/F1=0.977/0.977/0.977 AUC=0.999 | Val: loss=0.5467 acc=0.9540 P/R/F1=0.952/0.957/0.954 AUC=0.989 | lr=0.000086\n",
      "âœ… [cbam_guided] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam_guided/best.pt (val_acc=0.9540)\n",
      "[cbam_guided] Epoch 08/10 | Train: loss=0.4679 acc=0.9826 P/R/F1=0.983/0.983/0.983 AUC=0.999 | Val: loss=0.5339 acc=0.9571 P/R/F1=0.955/0.960/0.957 AUC=0.991 | lr=0.000056\n",
      "âœ… [cbam_guided] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam_guided/best.pt (val_acc=0.9571)\n",
      "[cbam_guided] Epoch 09/10 | Train: loss=0.4629 acc=0.9858 P/R/F1=0.986/0.986/0.986 AUC=0.999 | Val: loss=0.5187 acc=0.9616 P/R/F1=0.960/0.964/0.961 AUC=0.996 | lr=0.000037\n",
      "âœ… [cbam_guided] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam_guided/best.pt (val_acc=0.9616)\n",
      "[cbam_guided] Epoch 10/10 | Train: loss=0.4564 acc=0.9894 P/R/F1=0.990/0.990/0.990 AUC=1.000 | Val: loss=0.5198 acc=0.9616 P/R/F1=0.959/0.964/0.961 AUC=0.995 | lr=0.000030\n",
      "\n",
      "ðŸ“Š Test Metrics â†’ Acc: 0.9611 | Precision: 0.9595 | Recall: 0.9661 | F1: 0.9618 | AUC: 0.9890\n",
      "\n",
      "===== Training: cbam_guided+L =====\n",
      "attention_mode=gcsa_loss | guided_loss=True | head_variant=base\n",
      "[cbam_guided+L] Epoch 01/10 | Train: loss=1.0141 acc=0.7315 P/R/F1=0.735/0.741/0.737 AUC=0.917 | Val: loss=0.9437 acc=0.7924 P/R/F1=0.797/0.804/0.792 AUC=0.949 | lr=0.000293\n",
      "âœ… [cbam_guided+L] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam_guided+L/best.pt (val_acc=0.7924)\n",
      "[cbam_guided+L] Epoch 02/10 | Train: loss=0.7539 acc=0.8871 P/R/F1=0.889/0.892/0.890 AUC=0.981 | Val: loss=0.7483 acc=0.8970 P/R/F1=0.900/0.903/0.899 AUC=0.983 | lr=0.000274\n",
      "âœ… [cbam_guided+L] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam_guided+L/best.pt (val_acc=0.8970)\n",
      "[cbam_guided+L] Epoch 03/10 | Train: loss=0.6767 acc=0.9274 P/R/F1=0.928/0.930/0.929 AUC=0.991 | Val: loss=0.7016 acc=0.9212 P/R/F1=0.920/0.924/0.921 AUC=0.987 | lr=0.000244\n",
      "âœ… [cbam_guided+L] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam_guided+L/best.pt (val_acc=0.9212)\n",
      "[cbam_guided+L] Epoch 04/10 | Train: loss=0.6420 acc=0.9441 P/R/F1=0.945/0.946/0.945 AUC=0.994 | Val: loss=0.6737 acc=0.9323 P/R/F1=0.931/0.935/0.932 AUC=0.990 | lr=0.000207\n",
      "âœ… [cbam_guided+L] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam_guided+L/best.pt (val_acc=0.9323)\n",
      "[cbam_guided+L] Epoch 05/10 | Train: loss=0.6120 acc=0.9586 P/R/F1=0.959/0.960/0.959 AUC=0.997 | Val: loss=0.6829 acc=0.9278 P/R/F1=0.929/0.933/0.929 AUC=0.985 | lr=0.000165\n",
      "[cbam_guided+L] Epoch 06/10 | Train: loss=0.5936 acc=0.9674 P/R/F1=0.968/0.969/0.968 AUC=0.997 | Val: loss=0.6360 acc=0.9515 P/R/F1=0.950/0.954/0.952 AUC=0.991 | lr=0.000123\n",
      "âœ… [cbam_guided+L] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam_guided+L/best.pt (val_acc=0.9515)\n",
      "[cbam_guided+L] Epoch 07/10 | Train: loss=0.5760 acc=0.9762 P/R/F1=0.977/0.977/0.977 AUC=0.998 | Val: loss=0.6376 acc=0.9480 P/R/F1=0.946/0.951/0.948 AUC=0.991 | lr=0.000086\n",
      "[cbam_guided+L] Epoch 08/10 | Train: loss=0.5655 acc=0.9814 P/R/F1=0.982/0.982/0.982 AUC=0.999 | Val: loss=0.6156 acc=0.9601 P/R/F1=0.959/0.962/0.960 AUC=0.992 | lr=0.000056\n",
      "âœ… [cbam_guided+L] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam_guided+L/best.pt (val_acc=0.9601)\n",
      "[cbam_guided+L] Epoch 09/10 | Train: loss=0.5557 acc=0.9854 P/R/F1=0.986/0.986/0.986 AUC=0.999 | Val: loss=0.6191 acc=0.9581 P/R/F1=0.956/0.961/0.958 AUC=0.993 | lr=0.000037\n",
      "[cbam_guided+L] Epoch 10/10 | Train: loss=0.5482 acc=0.9904 P/R/F1=0.991/0.990/0.991 AUC=1.000 | Val: loss=0.6121 acc=0.9631 P/R/F1=0.961/0.966/0.963 AUC=0.992 | lr=0.000030\n",
      "âœ… [cbam_guided+L] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam_guided+L/best.pt (val_acc=0.9631)\n",
      "\n",
      "ðŸ“Š Test Metrics â†’ Acc: 0.9606 | Precision: 0.9589 | Recall: 0.9653 | F1: 0.9612 | AUC: 0.9928\n",
      "\n",
      "===== Training: cbam_guided+L+HeadX =====\n",
      "attention_mode=gcsa_loss | guided_loss=True | head_variant=heavy\n",
      "[cbam_guided+L+HeadX] Epoch 01/10 | Train: loss=1.0194 acc=0.7164 P/R/F1=0.723/0.723/0.722 AUC=0.912 | Val: loss=0.8575 acc=0.8232 P/R/F1=0.830/0.826/0.822 AUC=0.963 | lr=0.000293\n",
      "âœ… [cbam_guided+L+HeadX] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam_guided+L+HeadX/best.pt (val_acc=0.8232)\n",
      "[cbam_guided+L+HeadX] Epoch 02/10 | Train: loss=0.7624 acc=0.8797 P/R/F1=0.882/0.885/0.883 AUC=0.979 | Val: loss=0.7417 acc=0.9005 P/R/F1=0.900/0.901/0.900 AUC=0.979 | lr=0.000274\n",
      "âœ… [cbam_guided+L+HeadX] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam_guided+L+HeadX/best.pt (val_acc=0.9005)\n",
      "[cbam_guided+L+HeadX] Epoch 03/10 | Train: loss=0.6923 acc=0.9176 P/R/F1=0.919/0.921/0.920 AUC=0.988 | Val: loss=0.7330 acc=0.9066 P/R/F1=0.907/0.908/0.905 AUC=0.984 | lr=0.000244\n",
      "âœ… [cbam_guided+L+HeadX] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam_guided+L+HeadX/best.pt (val_acc=0.9066)\n",
      "[cbam_guided+L+HeadX] Epoch 04/10 | Train: loss=0.6586 acc=0.9370 P/R/F1=0.938/0.939/0.939 AUC=0.992 | Val: loss=0.6868 acc=0.9298 P/R/F1=0.929/0.933/0.930 AUC=0.986 | lr=0.000207\n",
      "âœ… [cbam_guided+L+HeadX] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam_guided+L+HeadX/best.pt (val_acc=0.9298)\n",
      "[cbam_guided+L+HeadX] Epoch 05/10 | Train: loss=0.6291 acc=0.9497 P/R/F1=0.951/0.951/0.951 AUC=0.995 | Val: loss=0.6693 acc=0.9379 P/R/F1=0.936/0.941/0.938 AUC=0.988 | lr=0.000165\n",
      "âœ… [cbam_guided+L+HeadX] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam_guided+L+HeadX/best.pt (val_acc=0.9379)\n",
      "[cbam_guided+L+HeadX] Epoch 06/10 | Train: loss=0.6065 acc=0.9605 P/R/F1=0.961/0.962/0.962 AUC=0.997 | Val: loss=0.6758 acc=0.9313 P/R/F1=0.931/0.934/0.932 AUC=0.987 | lr=0.000123\n",
      "[cbam_guided+L+HeadX] Epoch 07/10 | Train: loss=0.5857 acc=0.9707 P/R/F1=0.971/0.971/0.971 AUC=0.998 | Val: loss=0.6498 acc=0.9520 P/R/F1=0.950/0.955/0.952 AUC=0.985 | lr=0.000086\n",
      "âœ… [cbam_guided+L+HeadX] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam_guided+L+HeadX/best.pt (val_acc=0.9520)\n",
      "[cbam_guided+L+HeadX] Epoch 08/10 | Train: loss=0.5729 acc=0.9777 P/R/F1=0.978/0.978/0.978 AUC=0.999 | Val: loss=0.6366 acc=0.9505 P/R/F1=0.949/0.953/0.951 AUC=0.990 | lr=0.000056\n",
      "[cbam_guided+L+HeadX] Epoch 09/10 | Train: loss=0.5678 acc=0.9790 P/R/F1=0.980/0.980/0.980 AUC=0.999 | Val: loss=0.6420 acc=0.9500 P/R/F1=0.948/0.954/0.950 AUC=0.986 | lr=0.000037\n",
      "[cbam_guided+L+HeadX] Epoch 10/10 | Train: loss=0.5577 acc=0.9853 P/R/F1=0.986/0.986/0.986 AUC=0.999 | Val: loss=0.6351 acc=0.9525 P/R/F1=0.951/0.956/0.953 AUC=0.987 | lr=0.000030\n",
      "âœ… [cbam_guided+L+HeadX] New best saved @ /kaggle/working/tumornet_runs/ablation_cbam_guided+L+HeadX/best.pt (val_acc=0.9525)\n",
      "\n",
      "ðŸ“Š Test Metrics â†’ Acc: 0.9576 | Precision: 0.9563 | Recall: 0.9628 | F1: 0.9585 | AUC: 0.9832\n",
      "\n",
      "=== Ablation Summary (sorted by Test Acc) ===\n",
      "                   tag attention_mode  guided_loss head_variant  test_acc  \\\n",
      "4          cbam_guided           gcsa        False         base  0.961131   \n",
      "5        cbam_guided+L      gcsa_loss         True         base  0.960626   \n",
      "0             baseline           none        False         base  0.960626   \n",
      "1         channel_only             ch        False         base  0.959616   \n",
      "6  cbam_guided+L+HeadX      gcsa_loss         True        heavy  0.957597   \n",
      "2         spatial_only             sp        False         base  0.956588   \n",
      "3                 cbam           cbam        False         base  0.952549   \n",
      "\n",
      "   improvement_vs_baseline(pp)   params  sec_per_image  \n",
      "4                     0.050480  1838219       0.001632  \n",
      "5                     0.000000  1838219       0.001632  \n",
      "0                     0.000000  1682263       0.001284  \n",
      "1                    -0.100959  1767511       0.001400  \n",
      "6                    -0.302877  2214731       0.001643  \n",
      "2                    -0.403836  1683145       0.001426  \n",
      "3                    -0.807673  1768393       0.001544  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved summary CSV â†’ /kaggle/working/tumornet_runs/ablation_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Ablation Pipeline: Spiral CNN + GCSA (+ Heavy Classifier Head option)\n",
    "# =========================================================\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# -----------------------------\n",
    "# Reproducibility\n",
    "# -----------------------------\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset\n",
    "# -----------------------------\n",
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None, class_order=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.classes = class_order if class_order is not None else ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.classes.index(self.labels[idx])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "    @staticmethod\n",
    "    def load_image_paths_labels(root_dir):\n",
    "        image_paths, labels = [], []\n",
    "        for category in sorted(os.listdir(root_dir)):\n",
    "            cat_path = os.path.join(root_dir, category)\n",
    "            if os.path.isdir(cat_path):\n",
    "                for img_name in os.listdir(cat_path):\n",
    "                    img_path = os.path.join(cat_path, img_name)\n",
    "                    if img_path.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff')):\n",
    "                        image_paths.append(img_path)\n",
    "                        labels.append(category)\n",
    "        return image_paths, labels\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(0.1, 0.1, 0.1, 0.05),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val_test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Blocks\n",
    "# -----------------------------\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p: float = 3.0, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.clamp(min=self.eps).pow(self.p)\n",
    "        x = F.avg_pool2d(x, (x.size(-2), x.size(-1)))\n",
    "        return x.pow(1.0 / self.p)\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, c: int, r: int = 16):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        red = max(8, c // r)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(c, red, 1, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(red, c, 1, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        w = self.fc(self.pool(x))\n",
    "        return x * w\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, c: int, r: int = 16):\n",
    "        super().__init__()\n",
    "        red = max(8, c // r)\n",
    "        self.avg_fc = nn.Sequential(nn.Conv2d(c, red, 1, bias=False), nn.ReLU(inplace=True), nn.Conv2d(red, c, 1, bias=False))\n",
    "        self.max_fc = nn.Sequential(nn.Conv2d(c, red, 1, bias=False), nn.ReLU(inplace=True), nn.Conv2d(red, c, 1, bias=False))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        avg = torch.mean(x, dim=(2,3), keepdim=True)\n",
    "        mx, _ = torch.max(x, dim=2, keepdim=True); mx, _ = torch.max(mx, dim=3, keepdim=True)\n",
    "        out = self.avg_fc(avg) + self.max_fc(mx)\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, k: int = 7):\n",
    "        super().__init__()\n",
    "        assert k in (3,7)\n",
    "        pad = 3 if k == 7 else 1\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=k, padding=pad, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        avg = torch.mean(x, dim=1, keepdim=True)\n",
    "        mx, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x_cat = torch.cat([avg, mx], dim=1)\n",
    "        return self.sigmoid(self.conv(x_cat))\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, c: int, r: int = 16, k: int = 7):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(c, r)\n",
    "        self.sa = SpatialAttention(k)\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x * self.ca(x)\n",
    "        x = x * self.sa(x)\n",
    "        return x\n",
    "\n",
    "class GuidedChannelSpatialAttention(nn.Module):\n",
    "    def __init__(self, c: int, r: int = 16, k: int = 7):\n",
    "        super().__init__()\n",
    "        self.cbam_ca = ChannelAttention(c, r)\n",
    "        self.cbam_sa = SpatialAttention(k)\n",
    "        red = max(16, c // 8)\n",
    "        self.guidance_head = nn.Sequential(\n",
    "            nn.Conv2d(c, red, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(red),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(red, 1, kernel_size=1, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        A = self.guidance_head(x)  # (B,1,H,W)\n",
    "        ca = self.cbam_ca(x)\n",
    "        gate = torch.mean(A, dim=(2,3), keepdim=True)\n",
    "        x = x * (ca * (0.5 + gate))\n",
    "        sa = self.cbam_sa(x)\n",
    "        sa = torch.clamp(0.5 * sa + 0.5 * A, 0.0, 1.0)\n",
    "        x = x * sa\n",
    "        return x, A\n",
    "\n",
    "class ConvBnAct(nn.Module):\n",
    "    def __init__(self, c_in: int, c_out: int, k: int = 3, s: int = 1, p=None, g: int = 1, dil: int = 1):\n",
    "        super().__init__()\n",
    "        if p is None:\n",
    "            p = dil * (k - 1) // 2\n",
    "        self.conv = nn.Conv2d(c_in, c_out, kernel_size=k, stride=s, padding=p, groups=g, bias=False, dilation=dil)\n",
    "        self.bn = nn.BatchNorm2d(c_out)\n",
    "        self.act = nn.SiLU(inplace=True)\n",
    "    def forward(self, x): return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, c_in: int, c_out: int, k: int = 3, s: int = 1, d: int = 1):\n",
    "        super().__init__()\n",
    "        self.dw = ConvBnAct(c_in, c_in, k=k, s=s, p=None, g=c_in, dil=d)\n",
    "        self.pw = ConvBnAct(c_in, c_out, k=1, s=1, p=0)\n",
    "    def forward(self, x): return self.pw(self.dw(x))\n",
    "\n",
    "class SpiralBlock(nn.Module):\n",
    "    def __init__(self, c: int):\n",
    "        super().__init__()\n",
    "        assert c % 3 == 0, \"Channels must be divisible by 3 for SpiralBlock\"\n",
    "        c_g = c // 3\n",
    "        self.dw1 = DepthwiseSeparableConv(c_g, c_g, k=3, s=1, d=1)\n",
    "        self.dw2 = DepthwiseSeparableConv(c_g, c_g, k=3, s=1, d=2)\n",
    "        self.dw3 = DepthwiseSeparableConv(c_g, c_g, k=3, s=1, d=3)\n",
    "        self.fuse = ConvBnAct(c_g*3, c_g*3, k=1, s=1, p=0)\n",
    "        self.se   = SEBlock(c_g*3, r=8)\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        c = x.shape[1]; c_g = c // 3\n",
    "        x1, x2, x3 = x[:, :c_g], x[:, c_g:2*c_g], x[:, 2*c_g:]\n",
    "        y = torch.cat([self.dw1(x1), self.dw2(x2), self.dw3(x3)], dim=1)\n",
    "        y = self.fuse(y)\n",
    "        y = self.se(y)\n",
    "        return x + y\n",
    "\n",
    "# -----------------------------\n",
    "# Stage-end attention wrappers\n",
    "# -----------------------------\n",
    "class IdentityAttn(nn.Module):\n",
    "    def __init__(self): super().__init__()\n",
    "    def forward(self, x):\n",
    "        B,_,H,W = x.shape\n",
    "        dummy = x.new_zeros(B,1,H,W)\n",
    "        return x, dummy\n",
    "\n",
    "class ChannelOnlyStage(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(c, r=8)\n",
    "    def forward(self, x):\n",
    "        out = x * self.ca(x)\n",
    "        B,_,H,W = out.shape\n",
    "        return out, out.new_zeros(B,1,H,W)\n",
    "\n",
    "class SpatialOnlyStage(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super().__init__()\n",
    "        self.sa = SpatialAttention(7)\n",
    "    def forward(self, x):\n",
    "        out = x * self.sa(x)\n",
    "        B,_,H,W = out.shape\n",
    "        return out, out.new_zeros(B,1,H,W)\n",
    "\n",
    "class CBAMStage(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super().__init__()\n",
    "        self.cbam = CBAM(c, r=8, k=7)\n",
    "    def forward(self, x):\n",
    "        out = self.cbam(x)\n",
    "        B,_,H,W = out.shape\n",
    "        return out, out.new_zeros(B,1,H,W)\n",
    "\n",
    "# -----------------------------\n",
    "# Residual block (pluggable)\n",
    "# -----------------------------\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, c: int, expand: int = 2, res_attn_type: str = \"cbam\"):\n",
    "        super().__init__()\n",
    "        mid = c * expand\n",
    "        self.block = nn.Sequential(\n",
    "            ConvBnAct(c, mid, k=1, s=1, p=0),\n",
    "            DepthwiseSeparableConv(mid, mid, k=3, s=1),\n",
    "            ConvBnAct(mid, c, k=1, s=1, p=0),\n",
    "        )\n",
    "        self.res_attn_type = res_attn_type\n",
    "        if res_attn_type == \"none\":\n",
    "            self.attn_mod = None\n",
    "        elif res_attn_type == \"ch\":\n",
    "            self.attn_mod = ChannelAttention(c, r=8)\n",
    "        elif res_attn_type == \"sp\":\n",
    "            self.attn_mod = SpatialAttention(7)\n",
    "        elif res_attn_type == \"cbam\":\n",
    "            self.attn_mod = CBAM(c, r=8)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown res_attn_type: {res_attn_type}\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        y = self.block(x)\n",
    "        if self.attn_mod is None:\n",
    "            pass\n",
    "        elif self.res_attn_type in (\"ch\", \"sp\"):\n",
    "            y = y * self.attn_mod(y)\n",
    "        elif self.res_attn_type == \"cbam\":\n",
    "            y = self.attn_mod(y)\n",
    "        return x + y\n",
    "\n",
    "# -----------------------------\n",
    "# Classifier heads\n",
    "# -----------------------------\n",
    "class ClassifierHead(nn.Module):\n",
    "    \"\"\"Original head (GeM -> BN -> Dropout -> gated FC -> logits)\"\"\"\n",
    "    def __init__(self, in_features: int, num_classes: int, hidden: int = 512, dropout: float = 0.25, num_samples: int = 4):\n",
    "        super().__init__()\n",
    "        self.bn = nn.BatchNorm1d(in_features)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.num_samples = num_samples\n",
    "        self.fc1 = nn.Linear(in_features, hidden, bias=False)\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(hidden, hidden // 2, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden // 2, hidden, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.fc_out = nn.Linear(hidden, num_classes)\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.bn(x)\n",
    "        if self.training and self.num_samples > 1:\n",
    "            outs = []\n",
    "            for _ in range(self.num_samples):\n",
    "                h = self.fc1(self.dropout(x))\n",
    "                g = self.gate(h)\n",
    "                outs.append(self.fc_out(h * g))\n",
    "            return torch.stack(outs, dim=0).mean(dim=0)\n",
    "        else:\n",
    "            h = self.fc1(self.dropout(x))\n",
    "            g = self.gate(h)\n",
    "            return self.fc_out(h * g)\n",
    "\n",
    "class ClassifierHeadTumorX(nn.Module):\n",
    "    \"\"\"\n",
    "    Slightly heavier head tailored for tumor classification:\n",
    "      - Concatenate GeM and AdaptiveMax pooled features (richer lesion cues)\n",
    "      - Two-layer MLP with GELU\n",
    "      - SE-style feature gate on the second hidden layer\n",
    "      - Multi-sample dropout (more samples)\n",
    "    Input dim is expected to be 2 * backbone_channels (GeM + GMP)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features: int, num_classes: int, hidden1: int = 768, hidden2: int = 384, dropout: float = 0.30, num_samples: int = 5):\n",
    "        super().__init__()\n",
    "        self.bn = nn.BatchNorm1d(in_features)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.num_samples = num_samples\n",
    "        self.fc1 = nn.Linear(in_features, hidden1, bias=False)\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2, bias=False)\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(hidden2, hidden2 // 2, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden2 // 2, hidden2, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.fc_out = nn.Linear(hidden2, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.bn(x)\n",
    "        if self.training and self.num_samples > 1:\n",
    "            outs = []\n",
    "            for _ in range(self.num_samples):\n",
    "                h1 = self.fc1(self.dropout(x))\n",
    "                h1 = F.gelu(h1)\n",
    "                h2 = self.fc2(self.dropout(h1))\n",
    "                h2 = F.gelu(h2)\n",
    "                g  = self.gate(h2)\n",
    "                outs.append(self.fc_out(h2 * g))\n",
    "            return torch.stack(outs, dim=0).mean(dim=0)\n",
    "        else:\n",
    "            h1 = self.fc1(self.dropout(x)); h1 = F.gelu(h1)\n",
    "            h2 = self.fc2(self.dropout(h1)); h2 = F.gelu(h2)\n",
    "            g  = self.gate(h2)\n",
    "            return self.fc_out(h2 * g)\n",
    "\n",
    "# -----------------------------\n",
    "# Full model with pluggable attention + head variant\n",
    "# -----------------------------\n",
    "class TumorNet(nn.Module):\n",
    "    \"\"\"\n",
    "    attention_mode:\n",
    "      'none'       -> residual: none,     stage-end: identity\n",
    "      'ch'         -> residual: channel,  stage-end: channel-only\n",
    "      'sp'         -> residual: spatial,  stage-end: spatial-only\n",
    "      'cbam'       -> residual: cbam,     stage-end: cbam\n",
    "      'gcsa'       -> residual: cbam,     stage-end: guided (no aux loss)\n",
    "      'gcsa_loss'  -> same as gcsa; training loop adds aux loss\n",
    "\n",
    "    head_variant:\n",
    "      'base'  -> original ClassifierHead on GeM features\n",
    "      'heavy' -> ClassifierHeadTumorX on [GeM || GMP] concatenated features (only used with proposed model)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes: int, in_ch: int = 3, base_c: int = 48, attention_mode: str = \"gcsa\", head_variant: str = \"base\"):\n",
    "        super().__init__()\n",
    "        c1, c2, c3, c4 = base_c, base_c*2, base_c*3, base_c*4\n",
    "\n",
    "        # residual attention choice\n",
    "        if attention_mode == \"none\":\n",
    "            res_type = \"none\"\n",
    "        elif attention_mode == \"ch\":\n",
    "            res_type = \"ch\"\n",
    "        elif attention_mode == \"sp\":\n",
    "            res_type = \"sp\"\n",
    "        else:\n",
    "            res_type = \"cbam\"\n",
    "\n",
    "        # stage-end attention choice\n",
    "        def stage_end(c):\n",
    "            if attention_mode == \"none\":\n",
    "                return IdentityAttn()\n",
    "            elif attention_mode == \"ch\":\n",
    "                return ChannelOnlyStage(c)\n",
    "            elif attention_mode == \"sp\":\n",
    "                return SpatialOnlyStage(c)\n",
    "            elif attention_mode == \"cbam\":\n",
    "                return CBAMStage(c)\n",
    "            elif attention_mode in (\"gcsa\",\"gcsa_loss\"):\n",
    "                return GuidedChannelSpatialAttention(c)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown attention_mode: {attention_mode}\")\n",
    "\n",
    "        # Stem\n",
    "        self.stem = nn.Sequential(\n",
    "            ConvBnAct(in_ch, c1, k=3, s=2),\n",
    "            ConvBnAct(c1, c1, k=3, s=1),\n",
    "            SEBlock(c1, r=8),\n",
    "        )\n",
    "\n",
    "        # Stages\n",
    "        self.stage1_block1 = ResidualBlock(c1, res_attn_type=res_type)\n",
    "        self.stage1_block2 = ResidualBlock(c1, res_attn_type=res_type)\n",
    "        self.stage1_end    = stage_end(c1)\n",
    "        self.down1  = ConvBnAct(c1, c2, k=3, s=2)\n",
    "\n",
    "        self.stage2_block1 = SpiralBlock(c2)\n",
    "        self.stage2_block2 = SpiralBlock(c2)\n",
    "        self.stage2_end    = stage_end(c2)\n",
    "        self.down2  = ConvBnAct(c2, c3, k=3, s=2)\n",
    "\n",
    "        self.stage3_block1 = ResidualBlock(c3, res_attn_type=res_type)\n",
    "        self.stage3_block2 = SpiralBlock(c3)\n",
    "        self.stage3_end    = stage_end(c3)\n",
    "        self.down3  = ConvBnAct(c3, c4, k=3, s=2)\n",
    "\n",
    "        self.stage4_block1 = ResidualBlock(c4, res_attn_type=res_type)\n",
    "        self.stage4_block2 = ResidualBlock(c4, res_attn_type=res_type)\n",
    "        self.stage4_end    = stage_end(c4)\n",
    "\n",
    "        # Head variants\n",
    "        self.attention_mode = attention_mode\n",
    "        self.head_variant = head_variant\n",
    "        if head_variant == \"base\":\n",
    "            self.pool = GeM()\n",
    "            self.head = ClassifierHead(c4, num_classes)\n",
    "        elif head_variant == \"heavy\":\n",
    "            self.pool_gem = GeM()\n",
    "            self.pool_max = nn.AdaptiveMaxPool2d(1)\n",
    "            self.head = ClassifierHeadTumorX(c4 * 2, num_classes)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown head_variant: {head_variant}\")\n",
    "\n",
    "        self.last_guidance = None\n",
    "\n",
    "    def forward(self, x: torch.Tensor, return_guidance: bool = False):\n",
    "        x = self.stem(x)\n",
    "\n",
    "        x = self.stage1_block1(x); x = self.stage1_block2(x); x, g1 = self.stage1_end(x)\n",
    "        x = self.down1(x)\n",
    "        x = self.stage2_block1(x); x = self.stage2_block2(x); x, g2 = self.stage2_end(x)\n",
    "        x = self.down2(x)\n",
    "        x = self.stage3_block1(x); x = self.stage3_block2(x); x, g3 = self.stage3_end(x)\n",
    "        x = self.down3(x)\n",
    "        x = self.stage4_block1(x); x = self.stage4_block2(x); x, g4 = self.stage4_end(x)\n",
    "\n",
    "        g_stack = torch.stack([\n",
    "            F.interpolate(g1, size=g4.shape[-2:], mode='bilinear', align_corners=False),\n",
    "            F.interpolate(g2, size=g4.shape[-2:], mode='bilinear', align_corners=False),\n",
    "            F.interpolate(g3, size=g4.shape[-2:], mode='bilinear', align_corners=False),\n",
    "            g4\n",
    "        ], dim=1)  # (B,4,1,H,W)\n",
    "        g_agg = torch.mean(g_stack, dim=1)\n",
    "        self.last_guidance = g_agg\n",
    "\n",
    "        if self.head_variant == \"base\":\n",
    "            pooled = self.pool(x).flatten(1)\n",
    "        else:  # heavy\n",
    "            gem = self.pool_gem(x).flatten(1)\n",
    "            gmp = self.pool_max(x).flatten(1)\n",
    "            pooled = torch.cat([gem, gmp], dim=1)\n",
    "\n",
    "        logits = self.head(pooled)\n",
    "        return (logits, g_agg) if return_guidance else logits\n",
    "\n",
    "# -----------------------------\n",
    "# Losses / Metrics\n",
    "# -----------------------------\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, smoothing: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        num_classes = pred.size(-1)\n",
    "        log_probs = F.log_softmax(pred, dim=-1)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (num_classes - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), 1 - self.smoothing)\n",
    "        return torch.mean(torch.sum(-true_dist * log_probs, dim=-1))\n",
    "\n",
    "def guided_attention_loss(guidance: torch.Tensor, is_positive: torch.Tensor) -> torch.Tensor:\n",
    "    B = guidance.size(0)\n",
    "    g = guidance.view(B, -1)\n",
    "    mean = g.mean(dim=1)\n",
    "    sparsity = g.mean(dim=1)\n",
    "    gy = torch.abs(guidance[:, :, 1:, :] - guidance[:, :, :-1, :]).mean(dim=(1,2,3))\n",
    "    gx = torch.abs(guidance[:, :, :, 1:] - guidance[:, :, :, :-1]).mean(dim=(1,2,3))\n",
    "    tv = (gx + gy) * 0.5\n",
    "\n",
    "    pos_mask = is_positive.float()\n",
    "    neg_mask = 1.0 - pos_mask\n",
    "\n",
    "    loss_pos = (1.0 - mean) + 0.3 * sparsity + 0.1 * tv\n",
    "    loss_neg = mean + 0.2 * tv\n",
    "    loss = (pos_mask * loss_pos + neg_mask * loss_neg).mean()\n",
    "    return loss\n",
    "\n",
    "def calculate_metrics(logits, labels, num_classes):\n",
    "    preds_cpu = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "    labels_cpu = labels.cpu().numpy()\n",
    "    precision = precision_score(labels_cpu, preds_cpu, average='macro', zero_division=1)\n",
    "    recall    = recall_score(labels_cpu, preds_cpu, average='macro', zero_division=1)\n",
    "    f1        = f1_score(labels_cpu, preds_cpu, average='macro', zero_division=1)\n",
    "    probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "    labels_one_hot = F.one_hot(torch.tensor(labels_cpu), num_classes=num_classes).numpy()\n",
    "    try:\n",
    "        auc = roc_auc_score(labels_one_hot, probs, average='macro', multi_class='ovr')\n",
    "    except Exception:\n",
    "        auc = 0.0\n",
    "    return precision, recall, f1, auc, preds_cpu, labels_cpu\n",
    "\n",
    "# -----------------------------\n",
    "# Train / Validate\n",
    "# -----------------------------\n",
    "def pos_mask_from_classes(class_names):\n",
    "    return {i: (0 if (\"no\" in cls.lower() and \"tumor\" in cls.lower()) else 1) for i, cls in enumerate(class_names)}\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, device, criterion, attn_weight, class_names, use_guided_loss):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    all_logits, all_labels = [], []\n",
    "    pos_map = pos_mask_from_classes(class_names)\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        logits, guidance = model(images, return_guidance=True)\n",
    "\n",
    "        cls_loss = criterion(logits, labels)\n",
    "        if use_guided_loss:\n",
    "            is_pos = torch.tensor([pos_map[int(l.item())] for l in labels], device=device, dtype=torch.float32)\n",
    "            attn_loss = guided_attention_loss(guidance, is_pos)\n",
    "            loss = cls_loss + attn_weight * attn_loss\n",
    "        else:\n",
    "            loss = cls_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        correct += (pred == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        all_logits.append(logits.detach())\n",
    "        all_labels.append(labels.detach())\n",
    "\n",
    "        del images, labels, logits, guidance\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    logits_cat = torch.cat(all_logits)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    precision, recall, f1, auc, _, _ = calculate_metrics(logits_cat, labels_cat, num_classes=len(class_names))\n",
    "    return total_loss / max(total,1), correct / max(total,1), precision, recall, f1, auc\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, device, criterion, attn_weight, class_names, use_guided_loss, save_guidance=False, out_dir=\"./\"):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    all_logits, all_labels = [], []\n",
    "    pos_map = pos_mask_from_classes(class_names)\n",
    "    g_save_dir = os.path.join(out_dir, \"guidance_maps_val\")\n",
    "    if save_guidance:\n",
    "        os.makedirs(g_save_dir, exist_ok=True)\n",
    "\n",
    "    for b_idx, (images, labels) in enumerate(loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        logits, guidance = model(images, return_guidance=True)\n",
    "\n",
    "        cls_loss = criterion(logits, labels)\n",
    "        if use_guided_loss:\n",
    "            is_pos = torch.tensor([pos_map[int(l.item())] for l in labels], device=device, dtype=torch.float32)\n",
    "            attn_loss = guided_attention_loss(guidance, is_pos)\n",
    "            loss = cls_loss + attn_weight * attn_loss\n",
    "        else:\n",
    "            loss = cls_loss\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        correct += (pred == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        all_logits.append(logits.detach())\n",
    "        all_labels.append(labels.detach())\n",
    "\n",
    "        if save_guidance and b_idx < 3:\n",
    "            g = guidance.clamp(0,1)\n",
    "            for i in range(min(g.shape[0], 4)):\n",
    "                save_image(g[i], os.path.join(g_save_dir, f\"batch{b_idx}_img{i}.png\"))\n",
    "\n",
    "        del images, labels, logits, guidance\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    logits_cat = torch.cat(all_logits)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    precision, recall, f1, auc, _, _ = calculate_metrics(logits_cat, labels_cat, num_classes=len(class_names))\n",
    "    return total_loss / max(total,1), correct / max(total,1), precision, recall, f1, auc\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluate on Test\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def evaluate_on_test(model, test_loader, class_names, device, plot_cm=True):\n",
    "    model.eval()\n",
    "    all_logits, all_labels = [], []\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        logits = model(images, return_guidance=False)\n",
    "        all_logits.append(logits)\n",
    "        all_labels.append(labels)\n",
    "        del images, labels, logits\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    logits_cat = torch.cat(all_logits)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    precision, recall, f1, auc, pred_class, true_class = calculate_metrics(logits_cat, labels_cat, num_classes=len(class_names))\n",
    "    acc = (pred_class == true_class).sum() / len(true_class)\n",
    "\n",
    "    print(f'\\nðŸ“Š Test Metrics â†’ Acc: {acc:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f} | AUC: {auc:.4f}')\n",
    "    if plot_cm:\n",
    "        cm = confusion_matrix(true_class, pred_class)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "        disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "        plt.title(\"Confusion Matrix (Test Set)\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    del logits_cat, labels_cat, all_logits, all_labels\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return float(acc), float(precision), float(recall), float(f1), float(auc)\n",
    "\n",
    "# -----------------------------\n",
    "# Utility: params and latency\n",
    "# -----------------------------\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "@torch.no_grad()\n",
    "def benchmark_latency(model, device, img_size=224, batch_size=16, iters=50, warmup=10):\n",
    "    model.eval()\n",
    "    dummy = torch.randn(batch_size, 3, img_size, img_size, device=device)\n",
    "    for _ in range(warmup):\n",
    "        _ = model(dummy, return_guidance=False)\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "    t0 = time.time()\n",
    "    for _ in range(iters):\n",
    "        _ = model(dummy, return_guidance=False)\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    total_imgs = iters * batch_size\n",
    "    return (t1 - t0) / total_imgs\n",
    "\n",
    "# -----------------------------\n",
    "# Paths / Hyperparams\n",
    "# -----------------------------\n",
    "train_root = '/kaggle/input/brain-tumor-data-18k/tumordata/Training'\n",
    "test_root  = '/kaggle/input/brain-tumor-data-18k/tumordata/Testing'\n",
    "\n",
    "BATCH_SIZE   = 16\n",
    "EPOCHS       = 10\n",
    "LR           = 3e-4\n",
    "ATTN_WEIGHT  = 0.2\n",
    "BASE_CH      = 48\n",
    "NUM_WORKERS  = 2\n",
    "OUT_DIR      = \"/kaggle/working/tumornet_runs\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "CLASS_ORDER = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
    "num_classes = len(CLASS_ORDER)\n",
    "\n",
    "# -----------------------------\n",
    "# Data split\n",
    "# -----------------------------\n",
    "train_image_paths, train_labels = BrainTumorDataset.load_image_paths_labels(train_root)\n",
    "test_image_paths,  test_labels  = BrainTumorDataset.load_image_paths_labels(test_root)\n",
    "\n",
    "val_paths, final_test_paths, val_labels, final_test_labels = train_test_split(\n",
    "    test_image_paths, test_labels, test_size=0.5, stratify=test_labels, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = BrainTumorDataset(train_image_paths, train_labels, transform=data_transforms['train'],    class_order=CLASS_ORDER)\n",
    "val_dataset   = BrainTumorDataset(val_paths,        val_labels,   transform=data_transforms['val_test'], class_order=CLASS_ORDER)\n",
    "test_dataset  = BrainTumorDataset(final_test_paths, final_test_labels, transform=data_transforms['val_test'], class_order=CLASS_ORDER)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=False)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=False)\n",
    "\n",
    "# -----------------------------\n",
    "# Training driver (one config)\n",
    "# -----------------------------\n",
    "def run_training(attention_mode: str, use_guided_loss: bool, tag: str, head_variant: str = \"base\"):\n",
    "    set_seed(42)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = TumorNet(num_classes=num_classes, in_ch=3, base_c=BASE_CH,\n",
    "                     attention_mode=attention_mode, head_variant=head_variant).to(device)\n",
    "\n",
    "    criterion = LabelSmoothingCrossEntropy(smoothing=0.1)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=LR*0.1)\n",
    "\n",
    "    run_dir = os.path.join(OUT_DIR, f\"ablation_{tag}\")\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    log_path = os.path.join(run_dir, \"log.csv\")\n",
    "    with open(log_path, \"w\") as f:\n",
    "        f.write(\"epoch,train_loss,train_acc,train_prec,train_rec,train_f1,train_auc,val_loss,val_acc,val_prec,val_rec,val_f1,val_auc,lr\\n\")\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_path = os.path.join(run_dir, \"best.pt\")\n",
    "\n",
    "    print(f\"\\n===== Training: {tag} =====\")\n",
    "    print(f\"attention_mode={attention_mode} | guided_loss={use_guided_loss} | head_variant={head_variant}\")\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        train_loss, train_acc, tr_p, tr_r, tr_f1, tr_auc = train_one_epoch(\n",
    "            model, train_loader, optimizer, device, criterion, ATTN_WEIGHT, CLASS_ORDER, use_guided_loss\n",
    "        )\n",
    "        val_loss, val_acc, va_p, va_r, va_f1, va_auc = validate(\n",
    "            model, val_loader, device, criterion, ATTN_WEIGHT, CLASS_ORDER, use_guided_loss,\n",
    "            save_guidance=(epoch==1 or epoch%5==0), out_dir=run_dir\n",
    "        )\n",
    "\n",
    "        scheduler.step()\n",
    "        lr_now = optimizer.param_groups[0]['lr']\n",
    "        print(f\"[{tag}] Epoch {epoch:02d}/{EPOCHS} | \"\n",
    "              f\"Train: loss={train_loss:.4f} acc={train_acc:.4f} P/R/F1={tr_p:.3f}/{tr_r:.3f}/{tr_f1:.3f} AUC={tr_auc:.3f} | \"\n",
    "              f\"Val: loss={val_loss:.4f} acc={val_acc:.4f} P/R/F1={va_p:.3f}/{va_r:.3f}/{va_f1:.3f} AUC={va_auc:.3f} | lr={lr_now:.6f}\")\n",
    "\n",
    "        with open(log_path, \"a\") as f:\n",
    "            f.write(f\"{epoch},{train_loss:.6f},{train_acc:.6f},{tr_p:.6f},{tr_r:.6f},{tr_f1:.6f},{tr_auc:.6f},\"\n",
    "                    f\"{val_loss:.6f},{val_acc:.6f},{va_p:.6f},{va_r:.6f},{va_f1:.6f},{va_auc:.6f},{lr_now:.8f}\\n\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save({\"epoch\": epoch, \"model_state\": model.state_dict(), \"classes\": CLASS_ORDER,\n",
    "                        \"cfg\": dict(BASE_CH=BASE_CH, attention_mode=attention_mode, guided_loss=use_guided_loss, head_variant=head_variant)}, best_path)\n",
    "            print(f\"âœ… [{tag}] New best saved @ {best_path} (val_acc={best_val_acc:.4f})\")\n",
    "\n",
    "    # load best for test\n",
    "    ckpt = torch.load(best_path, map_location=device)\n",
    "    model.load_state_dict(ckpt[\"model_state\"])\n",
    "\n",
    "    # Metrics on test\n",
    "    test_acc, test_prec, test_rec, test_f1, test_auc = evaluate_on_test(model, test_loader, CLASS_ORDER, device, plot_cm=False)\n",
    "\n",
    "    # Params & Latency\n",
    "    n_params = count_params(model)\n",
    "    latency = benchmark_latency(model, device, img_size=224, batch_size=16, iters=50, warmup=10)\n",
    "\n",
    "    return {\n",
    "        \"tag\": tag,\n",
    "        \"attention_mode\": attention_mode,\n",
    "        \"guided_loss\": use_guided_loss,\n",
    "        \"head_variant\": head_variant,\n",
    "        \"test_acc\": test_acc,\n",
    "        \"test_precision\": test_prec,\n",
    "        \"test_recall\": test_rec,\n",
    "        \"test_f1\": test_f1,\n",
    "        \"test_auc\": test_auc,\n",
    "        \"params\": n_params,\n",
    "        \"sec_per_image\": latency\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# Ablation suite\n",
    "# -----------------------------\n",
    "ABLATIONS = [\n",
    "    dict(tag=\"baseline\",      attention_mode=\"none\",      guided_loss=False, head_variant=\"base\"),\n",
    "    dict(tag=\"channel_only\",  attention_mode=\"ch\",        guided_loss=False, head_variant=\"base\"),\n",
    "    dict(tag=\"spatial_only\",  attention_mode=\"sp\",        guided_loss=False, head_variant=\"base\"),\n",
    "    dict(tag=\"cbam\",          attention_mode=\"cbam\",      guided_loss=False, head_variant=\"base\"),\n",
    "    dict(tag=\"cbam_guided\",   attention_mode=\"gcsa\",      guided_loss=False, head_variant=\"base\"),\n",
    "    dict(tag=\"cbam_guided+L\", attention_mode=\"gcsa_loss\", guided_loss=True,  head_variant=\"base\"),\n",
    "    # New: Proposed model + Heavy classifier head\n",
    "    dict(tag=\"cbam_guided+L+HeadX\", attention_mode=\"gcsa_loss\", guided_loss=True, head_variant=\"heavy\"),\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# Run all ablations\n",
    "# -----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "results = []\n",
    "for cfg in ABLATIONS:\n",
    "    res = run_training(attention_mode=cfg[\"attention_mode\"],\n",
    "                       use_guided_loss=cfg[\"guided_loss\"],\n",
    "                       tag=cfg[\"tag\"],\n",
    "                       head_variant=cfg.get(\"head_variant\",\"base\"))\n",
    "    results.append(res)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# -----------------------------\n",
    "# Summarize & save\n",
    "# -----------------------------\n",
    "df = pd.DataFrame(results)\n",
    "baseline_acc = float(df.loc[df[\"tag\"]==\"baseline\",\"test_acc\"].values[0])\n",
    "df[\"improvement_vs_baseline(pp)\"] = (df[\"test_acc\"] - baseline_acc) * 100.0\n",
    "df_sorted = df.sort_values(\"test_acc\", ascending=False)\n",
    "\n",
    "OUT_SUMMARY = os.path.join(OUT_DIR, \"ablation_summary.csv\")\n",
    "df_sorted.to_csv(OUT_SUMMARY, index=False)\n",
    "\n",
    "print(\"\\n=== Ablation Summary (sorted by Test Acc) ===\")\n",
    "print(df_sorted[[\"tag\",\"attention_mode\",\"guided_loss\",\"head_variant\",\"test_acc\",\"improvement_vs_baseline(pp)\",\"params\",\"sec_per_image\"]])\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(df_sorted[\"tag\"], df_sorted[\"test_acc\"])\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.title(\"Ablation: Test Accuracy by Configuration\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSaved summary CSV â†’ {OUT_SUMMARY}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Optional inference helper\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def predict_images(model, image_paths, class_names=CLASS_ORDER, img_size=224, out_dir=OUT_DIR, device=device):\n",
    "    tf = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ])\n",
    "    model.eval()\n",
    "    os.makedirs(os.path.join(out_dir, \"guidance_maps_infer\"), exist_ok=True)\n",
    "    results = []\n",
    "    for p in image_paths:\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        x = tf(img).unsqueeze(0).to(device)\n",
    "        logits, g = model(x, return_guidance=True)\n",
    "        probs = torch.softmax(logits, dim=1).squeeze(0).cpu().numpy()\n",
    "        pred_idx = int(np.argmax(probs))\n",
    "        results.append({\"path\": p, \"pred\": class_names[pred_idx], \"probs\": {class_names[i]: float(probs[i]) for i in range(len(class_names))}})\n",
    "        save_image(g.clamp(0,1), os.path.join(out_dir, \"guidance_maps_infer\", os.path.basename(p) + \"_guidance.png\"))\n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5720575,
     "sourceId": 9418833,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14652.053551,
   "end_time": "2025-09-21T23:04:51.082606",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-21T19:00:39.029055",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
